{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machines for MNIST Digit Recognition \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "from sklearn import svm, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# For loading MNIST data. Code already implemented in the mnist_loader.py file.\n",
    "import mnist_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_set, validation_set, test_set = mnist_loader.load_data()\n",
    "\n",
    "training_data = training_set[0]\n",
    "training_data_labels = training_set[1]\n",
    "\n",
    "test_data = test_set[0]\n",
    "test_data_labels = test_set[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " The ``training_data`` is returned as a tuple with two entries.\n",
    "The first entry contains the actual training images.  This is a\n",
    "numpy ndarray with 50,000 entries.  Each entry is, in turn, a\n",
    "numpy ndarray with 784 values, representing the 28 * 28 = 784\n",
    "pixels in a single MNIST image.\n",
    "\n",
    "The second entry in the ``training_data`` tuple is a numpy ndarray\n",
    "containing 50,000 entries.  Those entries are just the digit\n",
    "values (0...9) for the corresponding images contained in the first\n",
    "entry of the tuple.\n",
    "\n",
    "The ``validation_data`` and ``test_data`` are similar, except\n",
    "each contains only 10,000 images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " ..., \n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]]\n",
      "No. of training images: 784\n",
      "No. of entries for each image: 50000\n"
     ]
    }
   ],
   "source": [
    "# Training data. We have 784 (28 * 28) data entries for each training image.\n",
    "print training_data\n",
    "print \"No. of training images: %s\" % len(training_data[0])\n",
    "print \"No. of entries for each image: %s\" % len(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5 0 4 ..., 8 4 8]\n"
     ]
    }
   ],
   "source": [
    "# Labels for training images\n",
    "print training_data_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "     verbose=0)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = svm.LinearSVC()\n",
    "classifier.fit(training_data , training_data_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<type 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "# Lets try our model on Test data.\n",
    "predicted_labels = classifier.predict(test_data)\n",
    "print np."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report for classifier LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
      "     verbose=0):\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      0.98      0.96       980\n",
      "          1       0.96      0.98      0.97      1135\n",
      "          2       0.93      0.88      0.91      1032\n",
      "          3       0.89      0.91      0.90      1010\n",
      "          4       0.92      0.93      0.92       982\n",
      "          5       0.88      0.85      0.87       892\n",
      "          6       0.93      0.95      0.94       958\n",
      "          7       0.92      0.92      0.92      1028\n",
      "          8       0.87      0.86      0.86       974\n",
      "          9       0.90      0.89      0.89      1009\n",
      "\n",
      "avg / total       0.92      0.92      0.91     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Classification report\n",
    "print \"Classification report for classifier %s:\\n%s\" % (\n",
    "        classifier, \n",
    "        metrics.classification_report(test_data_labels, predicted_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      "[[ 959    0    2    1    0    6    8    2    2    0]\n",
      " [   0 1113    4    1    0    1    4    1   11    0]\n",
      " [  10    9  910   23   11    4   12   10   40    3]\n",
      " [   5    2   19  915    3   20    5   12   20    9]\n",
      " [   1    3    5    3  914    0   10    3    6   37]\n",
      " [  10    3    1   38   11  761   20    8   31    9]\n",
      " [   9    4    7    2    6   20  907    1    2    0]\n",
      " [   2    9   21    6    6    1    1  945    4   33]\n",
      " [   8   13    8   23   13   38    8   15  835   13]\n",
      " [   6    8    2   15   34   10    0   27   13  894]]\n"
     ]
    }
   ],
   "source": [
    "# confusion matrix\n",
    "print(\"Confusion matrix:\\n%s\" % metrics.confusion_matrix(\n",
    "                                    test_data_labels, \n",
    "                                    predicted_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test data Result: 9153 / 10000, Percentage: 0.915300\n"
     ]
    }
   ],
   "source": [
    "#Lets check the model's accuracy on the test data.\n",
    "n_correct_predictions = sum([int(x==y) for x,y in zip(\n",
    "                            test_data_labels, predicted_labels)])\n",
    "print \"Test data Result: %s / %s, Percentage: %f\" % (\n",
    "            n_correct_predictions,\n",
    "            len(test_data),\n",
    "            np.float(n_correct_predictions)/len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
